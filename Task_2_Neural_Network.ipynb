{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 2 Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1-M2ICC8fiqDT71zUyUqv_e8VrOghKiLo",
      "authorship_tag": "ABX9TyNVamUJU6aLRvTSvdyyUiQ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkritiGhosh/DeeperSystemAssignment/blob/master/Task_2_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YJpvrTwRBlJ",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network Assignment\n",
        "Question link - https://gist.github.com/csaftoiu/9fccaf47fd8f96cd378afd8fdd0d63c1\n",
        "\n",
        "By - Akriti Ghosh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZgzb5ipRBhm",
        "colab_type": "text"
      },
      "source": [
        "Importing dataset using the link provided in the question link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7to8waqAHt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "2065928d-d51c-4466-df5b-c6fe404af78e"
      },
      "source": [
        "!wget https://www.dropbox.com/s/lbobq9xt3nchq5q/train.rotfaces.zip?dl=0 \\\n",
        "  -O /train.rotfaces.zip\n",
        "!wget  https://www.dropbox.com/s/ustfubunhfe47mj/test.rotfaces.zip?dl=0 \\\n",
        "  -O /test.rotfaces.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-13 06:03:52--  https://www.dropbox.com/s/lbobq9xt3nchq5q/train.rotfaces.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.1, 2620:100:601d:1::a27d:501\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/lbobq9xt3nchq5q/train.rotfaces.zip [following]\n",
            "--2020-08-13 06:03:53--  https://www.dropbox.com/s/raw/lbobq9xt3nchq5q/train.rotfaces.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc7e3d7357b35be778adc799c7c7.dl.dropboxusercontent.com/cd/0/inline/A9UwqkD2vZx6CjEiKwB1CY32qHAigDC0nRmO-Ydqnf6MiYou-AVAXx5pLrRW0ly-I5wpkYphTEn4jrqD72d4wEa8DwLZlrijhRpl9JxCDmJ88A/file# [following]\n",
            "--2020-08-13 06:03:54--  https://uc7e3d7357b35be778adc799c7c7.dl.dropboxusercontent.com/cd/0/inline/A9UwqkD2vZx6CjEiKwB1CY32qHAigDC0nRmO-Ydqnf6MiYou-AVAXx5pLrRW0ly-I5wpkYphTEn4jrqD72d4wEa8DwLZlrijhRpl9JxCDmJ88A/file\n",
            "Resolving uc7e3d7357b35be778adc799c7c7.dl.dropboxusercontent.com (uc7e3d7357b35be778adc799c7c7.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc7e3d7357b35be778adc799c7c7.dl.dropboxusercontent.com (uc7e3d7357b35be778adc799c7c7.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/A9Ww7YBeT-jcpi65egaU3kZTcjb-MRb8HfBfQ33j3XuV2LaeMITopwh0kQEAJNfSrrx1viCh_HqKRpC1iBHRnrLdnxZhrVAuNTVWBe8izHNOssRKbkXGpOtqtibR1ndowD-U6LuViw0EGbpeMf1WucMGujbrH0jFogMQV_cNH_o2lSlw1q_n2nl8YIxTCQH7pHzTFYwgNlHWbkLb0y84unVO9XppduhTrSmbKJLD_Bhhh2u03_CTj9uipWzghSXdaraZtEIKyjZ9QLO49XmrNN1m3NcHGqFjVemCE8eo6uMG4I1vd18lDd7LQH5hp21V-ExyFmcixxiCd6k_sFy1Uu2h/file [following]\n",
            "--2020-08-13 06:03:55--  https://uc7e3d7357b35be778adc799c7c7.dl.dropboxusercontent.com/cd/0/inline2/A9Ww7YBeT-jcpi65egaU3kZTcjb-MRb8HfBfQ33j3XuV2LaeMITopwh0kQEAJNfSrrx1viCh_HqKRpC1iBHRnrLdnxZhrVAuNTVWBe8izHNOssRKbkXGpOtqtibR1ndowD-U6LuViw0EGbpeMf1WucMGujbrH0jFogMQV_cNH_o2lSlw1q_n2nl8YIxTCQH7pHzTFYwgNlHWbkLb0y84unVO9XppduhTrSmbKJLD_Bhhh2u03_CTj9uipWzghSXdaraZtEIKyjZ9QLO49XmrNN1m3NcHGqFjVemCE8eo6uMG4I1vd18lDd7LQH5hp21V-ExyFmcixxiCd6k_sFy1Uu2h/file\n",
            "Reusing existing connection to uc7e3d7357b35be778adc799c7c7.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 162657090 (155M) [application/zip]\n",
            "Saving to: ‘/train.rotfaces.zip’\n",
            "\n",
            "/train.rotfaces.zip 100%[===================>] 155.12M  42.8MB/s    in 3.6s    \n",
            "\n",
            "2020-08-13 06:03:59 (42.8 MB/s) - ‘/train.rotfaces.zip’ saved [162657090/162657090]\n",
            "\n",
            "--2020-08-13 06:04:03--  https://www.dropbox.com/s/ustfubunhfe47mj/test.rotfaces.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.1, 2620:100:601d:1::a27d:501\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ustfubunhfe47mj/test.rotfaces.zip [following]\n",
            "--2020-08-13 06:04:03--  https://www.dropbox.com/s/raw/ustfubunhfe47mj/test.rotfaces.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucba866abd7e6f825e16eab356c2.dl.dropboxusercontent.com/cd/0/inline/A9VeNhpMcUZ-BIyYjeye10KCNLk6cDobJab31tAM5V2GIngF2_REJVyh4jSXUsZ0wGuA35BbKIGNio6kSbVrwhDQHj8a95GF4jse2-QAwxVvWw/file# [following]\n",
            "--2020-08-13 06:04:03--  https://ucba866abd7e6f825e16eab356c2.dl.dropboxusercontent.com/cd/0/inline/A9VeNhpMcUZ-BIyYjeye10KCNLk6cDobJab31tAM5V2GIngF2_REJVyh4jSXUsZ0wGuA35BbKIGNio6kSbVrwhDQHj8a95GF4jse2-QAwxVvWw/file\n",
            "Resolving ucba866abd7e6f825e16eab356c2.dl.dropboxusercontent.com (ucba866abd7e6f825e16eab356c2.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucba866abd7e6f825e16eab356c2.dl.dropboxusercontent.com (ucba866abd7e6f825e16eab356c2.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/A9U2-uRV96iVf8mqJXXbfzDh7WMVP0hhLeo4mJmIc_YRMUZaXljmBV6qaq6clPdtvDgTfR14W6GBrSU0wWHzgBQW9Lorkjti_Ix2740gFlXhYrvnoSHOMYpAmmjw2zrT5Aih_5MGCtUvU2Zrx8UKav43QkQNwZ0S21-p7O7YE1i_OstZ9XYtTKhBHgOikiPbFO0dpTO_UCWO9yRpenhppfp4MCsgMaPxiDFqeMcbCFRodA05nes1JZLdB7IX2xT6CXkSl1cAkxyhAHfkCFFdyRQJhCA6bA8_x9I5AdcryCUHuYa8BuTa2LdHyMw5oZ1h12OXh9IAkzKYhJ6slwOZUI0s/file [following]\n",
            "--2020-08-13 06:04:04--  https://ucba866abd7e6f825e16eab356c2.dl.dropboxusercontent.com/cd/0/inline2/A9U2-uRV96iVf8mqJXXbfzDh7WMVP0hhLeo4mJmIc_YRMUZaXljmBV6qaq6clPdtvDgTfR14W6GBrSU0wWHzgBQW9Lorkjti_Ix2740gFlXhYrvnoSHOMYpAmmjw2zrT5Aih_5MGCtUvU2Zrx8UKav43QkQNwZ0S21-p7O7YE1i_OstZ9XYtTKhBHgOikiPbFO0dpTO_UCWO9yRpenhppfp4MCsgMaPxiDFqeMcbCFRodA05nes1JZLdB7IX2xT6CXkSl1cAkxyhAHfkCFFdyRQJhCA6bA8_x9I5AdcryCUHuYa8BuTa2LdHyMw5oZ1h12OXh9IAkzKYhJ6slwOZUI0s/file\n",
            "Reusing existing connection to ucba866abd7e6f825e16eab356c2.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17585243 (17M) [application/zip]\n",
            "Saving to: ‘/test.rotfaces.zip’\n",
            "\n",
            "/test.rotfaces.zip  100%[===================>]  16.77M  54.0MB/s    in 0.3s    \n",
            "\n",
            "2020-08-13 06:04:05 (54.0 MB/s) - ‘/test.rotfaces.zip’ saved [17585243/17585243]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2SeHyxiRZRB",
        "colab_type": "text"
      },
      "source": [
        "Unzipping the datasets and storing it in folder in colab file storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tofPVYnC0yQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_train = zipfile.ZipFile('/train.rotfaces.zip','r')\n",
        "zip_train.extractall('train.rotfaces')\n",
        "zip_train.close()\n",
        "\n",
        "zip_test = zipfile.ZipFile('/test.rotfaces.zip','r')\n",
        "zip_test.extractall('test.rotfaces')\n",
        "zip_test.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06sMmZ4YRmbB",
        "colab_type": "text"
      },
      "source": [
        "Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgYKJkIhziVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files # For downloading csv and h5 files\n",
        "import csv # Editting the csv file\n",
        "import pandas as pd # Mathematical manipulation of data\n",
        "import glob # Accessing files in a folder\n",
        "import numpy as np # Create and manipulate arrays\n",
        "from PIL import Image # Display and manipulate images\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder # To encode the labels from string to int \n",
        "from sklearn.model_selection import train_test_split # To split the training dataset for validation\n",
        "\n",
        "from keras.utils import to_categorical # Categorization of labels in training data\n",
        "from keras.preprocessing import image # Loading, Accessing & manipulating images \n",
        "\n",
        "# Models, Layers, Optimizers used (Tensorflow)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oju4878_7lp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Storing the path of training data images\n",
        "train = 'train.rotfaces/train/'\n",
        "# Storing the csv file as a Pandas DataFrame\n",
        "train_df = pd.read_csv('/content/train.rotfaces/train.truth.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T04TeWJ6S7T0",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "1.  Encoding the labels from string value to integers\n",
        "2.  Reading the images from training & testing dataset and storing them in a numpy array of names **X** & **x_test** respectively\n",
        "3.  Storing the names of the images  in testing dataset in a list called **fn**\n",
        "4.  Splitting the X and Y of training dataset into train & test data for validation in the ratio of 80-20\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8S_9p_m8weI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "label = encoder.fit_transform(train_df.iloc[:, -1].values)\n",
        "value = train_df.iloc[:, 1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUOJoYPT0yMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image = []\n",
        "for i in (train_df.iloc[:,0]):\n",
        "    img = image.load_img(train+ i,target_size=(64,64,3))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AZh7jue9wcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_image = []\n",
        "fn = []\n",
        "for i in glob.glob('/content/test.rotfaces/test/*.jpg'):\n",
        "  fn.append(i.split('/')[-1])\n",
        "  img = image.load_img( i,target_size=(64,64,3))\n",
        "  img = image.img_to_array(img)\n",
        "  img = img/255\n",
        "  test_image.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC7X9TUf_BFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(train_image)\n",
        "x_test = np.array(test_image)\n",
        "Y = to_categorical(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-2mRkjXTdQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,  test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr9APM7hUNfl",
        "colab_type": "text"
      },
      "source": [
        "# Model Creation and Predictions\n",
        "Two models are used for the classifiction of images.\n",
        "1.  CIFAR10 Keras model - https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py\n",
        "\n",
        "2. My Custom CNN model : This model uses lesser layers, and gives more accurate prediction in less time than the CIFAR_CNN model. In this, lesser number of Convolution layer & MaxPooling layers, and more Dense layer are used compared to the CIFAR10 model.\n",
        "\n",
        "The Optimizers used are :\n",
        "1. CIFAR10 - RMSProp\n",
        "2. My CNN - Adam\n",
        "\n",
        "The epoch & batch size of both the models are same, ie, 5 and 256 respectively\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZI6sKwyUgo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TprEOoRJLhSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10 = Sequential()\n",
        "cifar10.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=X.shape[1:]))\n",
        "cifar10.add(Activation('relu'))\n",
        "cifar10.add(Conv2D(32, (3, 3)))\n",
        "cifar10.add(Activation('relu'))\n",
        "cifar10.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cifar10.add(Dropout(0.25))\n",
        "\n",
        "cifar10.add(Conv2D(64, (3, 3), padding='same'))\n",
        "cifar10.add(Activation('relu'))\n",
        "cifar10.add(Conv2D(64, (3, 3)))\n",
        "cifar10.add(Activation('relu'))\n",
        "cifar10.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cifar10.add(Dropout(0.25))\n",
        "\n",
        "cifar10.add(Flatten())\n",
        "cifar10.add(Dense(512))\n",
        "cifar10.add(Activation('relu'))\n",
        "cifar10.add(Dropout(0.5))\n",
        "cifar10.add(Dense(4))\n",
        "cifar10.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the cifar10 using RMSprop\n",
        "cifar10.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHByPoqqKkq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "be6ec20c-b7f8-4267-c9a7-9ce0aa04e4d1"
      },
      "source": [
        "cifar10.fit(x=X_train,y= y_train, \n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(X_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "scores = cifar10.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "153/153 [==============================] - 21s 138ms/step - loss: 0.9102 - accuracy: 0.6286 - val_loss: 0.5184 - val_accuracy: 0.8187\n",
            "Epoch 2/5\n",
            "153/153 [==============================] - 20s 130ms/step - loss: 0.4310 - accuracy: 0.8388 - val_loss: 0.3023 - val_accuracy: 0.8882\n",
            "Epoch 3/5\n",
            "153/153 [==============================] - 20s 131ms/step - loss: 0.2954 - accuracy: 0.8899 - val_loss: 0.2298 - val_accuracy: 0.9172\n",
            "Epoch 4/5\n",
            "153/153 [==============================] - 20s 130ms/step - loss: 0.2213 - accuracy: 0.9206 - val_loss: 0.1772 - val_accuracy: 0.9395\n",
            "Epoch 5/5\n",
            "153/153 [==============================] - 20s 131ms/step - loss: 0.1722 - accuracy: 0.9401 - val_loss: 0.1444 - val_accuracy: 0.9502\n",
            "306/306 [==============================] - 3s 9ms/step - loss: 0.1444 - accuracy: 0.9502\n",
            "Test loss: 0.14444614946842194\n",
            "Test accuracy: 0.9502044916152954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC7uXaWNJEJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_cnn = tf.keras.models.Sequential([\n",
        "                                    Conv2D(32, (3,3), activation='relu', input_shape = X.shape[1:], padding='same'),\n",
        "                                    MaxPooling2D(2,2),\n",
        "                                    Conv2D(32, (3,3), activation='relu'),\n",
        "                                    MaxPooling2D(2,2),\n",
        "                                    Conv2D(64, (3,3), activation='relu'),\n",
        "                                    MaxPooling2D(2,2),\n",
        "                                    Flatten(),\n",
        "                                    Dense(128, activation='relu'),\n",
        "                                    Dense(64, activation='relu'),\n",
        "                                    Dense(4, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIaWctEHN1JP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c45a259b-3222-452c-8324-47c49b3771c1"
      },
      "source": [
        "my_cnn.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "my_cnn.fit(x=X_train,y= y_train, \n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(X_test, y_test),\n",
        "              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "153/153 [==============================] - 7s 46ms/step - loss: 0.6114 - accuracy: 0.7527 - val_loss: 0.3163 - val_accuracy: 0.8817\n",
            "Epoch 2/5\n",
            "153/153 [==============================] - 7s 43ms/step - loss: 0.2114 - accuracy: 0.9247 - val_loss: 0.1774 - val_accuracy: 0.9380\n",
            "Epoch 3/5\n",
            "153/153 [==============================] - 7s 43ms/step - loss: 0.1323 - accuracy: 0.9551 - val_loss: 0.1421 - val_accuracy: 0.9491\n",
            "Epoch 4/5\n",
            "153/153 [==============================] - 7s 43ms/step - loss: 0.0932 - accuracy: 0.9686 - val_loss: 0.1339 - val_accuracy: 0.9563\n",
            "Epoch 5/5\n",
            "153/153 [==============================] - 7s 43ms/step - loss: 0.0746 - accuracy: 0.9750 - val_loss: 0.0989 - val_accuracy: 0.9656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0880029b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o2QJOpKM9us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "bf8fc6a2-fedd-4429-ea24-c07a2d495eae"
      },
      "source": [
        "my_cnn.summary()\n",
        "# my_cnn_name = 'cnn_967_e5_b256_l10.h5'\n",
        "# my_cnn.save(my_cnn_name)\n",
        "# files.download(my_cnn_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 332,196\n",
            "Trainable params: 332,196\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_929144a1-882a-438b-a917-958934b5ad54\", \"cnn_967_e5_b256_l10.h5\", 4047872)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVRpJmJilUKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0eb80834-9a12-4ef5-cf9c-f9ba3acab810"
      },
      "source": [
        "# The testing accuracy of my_cnn model\n",
        "scores = my_cnn.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "306/306 [==============================] - 1s 5ms/step - loss: 0.0989 - accuracy: 0.9656\n",
            "Test loss: 0.0988747626543045\n",
            "Test accuracy: 0.9656441807746887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRD5HMxV1Tl",
        "colab_type": "text"
      },
      "source": [
        "# Using the model to correct the test dataset (the images in test.rotfaces)\n",
        "\n",
        "1. Predicting values for x_test and saving it in y_pred\n",
        "2. Predicting the rotation in faces using y_pred and saving the string value in test_label list\n",
        "3. Rotating the images according to the predictions and storing the image arrays in a numpy array called correction\n",
        "4. Mounting the Google Drive and storing the corrected images in the drive\n",
        "5. Creating a DataFrame of test images file names (fn) and the predicted labels (test_labels) and storing it in a csv file called **test.preds.csv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkaKUiSVkmB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8e6fcdf5-598d-4fb3-97db-2f1b134f3acd"
      },
      "source": [
        "y_pred = my_cnn.predict_classes(x_test)\n",
        "cifar_pred = cifar10.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-ee6987fe87ce>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNM48jiCBF4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "133ed25f-3d79-4811-fcee-b4f0f545ce91"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gHRf2u4YUWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_label = []\n",
        "crrt_cifar_img = []\n",
        "for i in range(len(cifar_pred)):\n",
        "  img = Image.fromarray((x_test[i]*255).astype(np.uint8))\n",
        "  # display(img)\n",
        "  if cifar_pred[i]==0:\n",
        "    # print('rotated_left')\n",
        "    cifar_label.append('rotated_left')\n",
        "    img = img.transpose(Image.ROTATE_270)\n",
        "  \n",
        "  elif cifar_pred[i]==1:\n",
        "    # print('rotated_right')\n",
        "    cifar_label.append('rotated_right')\n",
        "    img = img.transpose(Image.ROTATE_90)\n",
        "  \n",
        "  elif cifar_pred[i]==2:\n",
        "    # print('upright')\n",
        "    cifar_label.append('upright')\n",
        "    # img = img.transpose() No transpose required\n",
        "  \n",
        "  else:\n",
        "    # print('rotated_left')\n",
        "    cifar_label.append('upside_down')\n",
        "    img = img.transpose(Image.ROTATE_180)\n",
        "  \n",
        "  fl_nm = str(fn[i].split('.')[0])+'.png'\n",
        "  crrt_cifar_img.append(np.array(img))\n",
        "  img = img.save('/content/drive/My Drive/taskNN/cifar_model/'+fl_nm)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWmILMfe6hxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_label = []\n",
        "correct_img = []\n",
        "for i in range(len(y_pred)):\n",
        "  img = Image.fromarray((x_test[i]*255).astype(np.uint8))\n",
        "  # display(img)\n",
        "  if y_pred[i]==0:\n",
        "    # print('rotated_left')\n",
        "    test_label.append('rotated_left')\n",
        "    img = img.transpose(Image.ROTATE_270)\n",
        "  \n",
        "  elif y_pred[i]==1:\n",
        "    # print('rotated_right')\n",
        "    test_label.append('rotated_right')\n",
        "    img = img.transpose(Image.ROTATE_90)\n",
        "  \n",
        "  elif y_pred[i]==2:\n",
        "    # print('upright')\n",
        "    test_label.append('upright')\n",
        "    # img = img.transpose() No transpose required\n",
        "  \n",
        "  else:\n",
        "    # print('rotated_left')\n",
        "    test_label.append('upside_down')\n",
        "    img = img.transpose(Image.ROTATE_180)\n",
        "  \n",
        "  fl_nm = str(fn[i].split('.')[0])+'.png'\n",
        "  correct_img.append(np.array(img))\n",
        "  img = img.save('/content/drive/My Drive/taskNN/my_model/'+fl_nm)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_ijBeU1sm95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = pd.DataFrame(index = fn, data = test_label)\n",
        "test_pred.to_csv('test.preds.csv')\n",
        "files.download('test.preds.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxhD4KgxI2BQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correction = np.array(correct_img)\n",
        "cifar_correction = np.array(crrt_cifar_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfvrBNuqZVax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = pd.DataFrame(index = fn, data = cifar_label)\n",
        "test_pred.to_csv('ctest.preds.csv')\n",
        "files.download('ctest.preds.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}